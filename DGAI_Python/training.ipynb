{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Pix2Pix\n",
    "Implementação baseada em https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "Desenvolvido por David Dória https://github.com/daversd para o programa\n",
    "2021-2022 B-pro Architectural Design RC4\n",
    "\n",
    "Pix2Pix é um modelo condicional de redes generativas adversárias (conditional generative adversarial network model - cGAN) que executa traduções imagem-para-imagem, aprendendo como executar esta operação a partir de pares de imagens (inputs e outputs esperados).\n",
    "Esta implementação utiliza imagens de `256x256 px` para o input e output, esperando o set de treinamento para estar já formatado e localizado em uma pasta que contenha as pastas `/AB/train/` e `AB/test/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar os pacotes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pix2pix_helpers.util as util\n",
    "from pix2pix_helpers.create_dataset import ImageFolderLoader\n",
    "from pix2pix_helpers.pix2pix_model import Pix2PixModel\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração high level\n",
    "Como regra geral, estas são as configurações que você precisará alterar.\n",
    "Notas importantes:\n",
    "- Utilize um set de treinamento que esteja na casa das centenas de imagens para ter um bom resultado. Quanto mais, melhor!\n",
    "- Caso esteja testando múltiplos sets de treinamento, e queira ter controle sobre os diferentes resultados de cada um, lembre de atualizar o valor de `MODEL_NAME`. Caso não o faça, as informações produzidas anteriormente serão sobrescritas.\n",
    "- 300 é um bom número para `EPOCHS` (épocas ou períodos de treinamento). Caso você utilize mais, acompanhe os resultados para garantir que os resultados não estão overfitting - quando o treinamento produz um modelo muito bom para o material específico de treinamento, mas incapaz de processar novas imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False            # Determina se o programa deve executar o treinamento\n",
    "TEST = False             # Determina se o programa deve executar o teste (carregando o último checkpoint)\n",
    "TEST_SAMPLE = 10         # Quantidade de imagens para testar\n",
    "WRITE_LOGS = True        # Determina se logs do tensorboard devem ser escritos para o disco\n",
    "SAVE_CKPTS = True        # Determina se checkpoints dever ser salvos\n",
    "SAVE_IMG_CKPT = True     # Determina se imagens do treinamento devem ser salvas para cada checkpoint\n",
    "EXPORT_MODEL = True      # Determina se o modelo deve ser salvo (carregando o último checkpoint)\n",
    "\n",
    "FOLDER_NAME = 'data/tracos'                             # O nome da pasta onde estão os arquivos de treinamento\n",
    "MODEL_NAME = 'tracos_run_1'                             # O nome do modelo que será treinado (o material do treinamento será salvo usando esse nome)\n",
    "LOAD_NUMBER = -1                                        # Número do checkpoint a ser carregado (-1 carrega o último)\n",
    "\n",
    "EPOCHS = 100                # Quantidade de épocas de treinamento. Deve ser número par\n",
    "\n",
    "PRINT_FREQ = 100            # Intervalo entre logs de treinamento no console, em passos\n",
    "LOG_FREQ = 100              # Intervalo entre logs tensorboard, em passos\n",
    "CKPT_FREQ = 10              # Intervalo entre checkpoints, em épocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalização de configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "\n",
    "CKPT_DIR = os.path.join('checkpoints', MODEL_NAME)      # Nome da pasta onde serão salvos os checkpoints\n",
    "LOG_DIR = 'runs/' + MODEL_NAME                          # Nome da pasta onde serão salvos o logs do tensorboard\n",
    "TEST_DIR = 'test/' + MODEL_NAME                         # Nome da pasta onde serão salvas as imagens de teste\n",
    "\n",
    "# Create the required folders\n",
    "if SAVE_CKPTS:\n",
    "    if not os.path.isdir(CKPT_DIR):\n",
    "        os.makedirs(CKPT_DIR)\n",
    "\n",
    "if WRITE_LOGS:\n",
    "    if not os.path.isdir(LOG_DIR):\n",
    "        os.makedirs(LOG_DIR)\n",
    "\n",
    "if SAVE_IMG_CKPT:\n",
    "    if not os.path.isdir(TEST_DIR):\n",
    "        os.makedirs(TEST_DIR)\n",
    "\n",
    "# Initialize the log writer\n",
    "if WRITE_LOGS:\n",
    "    writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para carregamento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model):\n",
    "    \"\"\"\n",
    "    Loads the networks from the checkpoint specified in LOAD_NUMBER\n",
    "    Use -1 to load the latest model.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_files = glob.glob(CKPT_DIR + '/*.pth')\n",
    "\n",
    "    if LOAD_NUMBER == -1:\n",
    "        file_path = max(list_of_files, key=os.path.getctime)\n",
    "        file_name = os.path.basename(file_path)\n",
    "        file_number = file_name.split('_')[0]\n",
    "        print(file_number)\n",
    "    else:\n",
    "        file_number = LOAD_NUMBER\n",
    "    \n",
    "    file_prefix = os.path.join(CKPT_DIR, str(file_number) + '_')\n",
    "    netG_File = file_prefix + 'net_G.pth'\n",
    "    netD_File = file_prefix + 'net_D.pth'\n",
    "    \n",
    "    files_exist = os.path.exists(netG_File) and os.path.exists(netD_File)\n",
    "    assert files_exist, f\"Checkpoint {LOAD_NUMBER} does not exist. Check '{CKPT_DIR}' to see available checkpoints\"\n",
    "    print(f\"Loading model from checkpoint {file_number} \\n\"+ f\"Generator is {netG_File} \\n\" + f\"Discriminator is {netD_File}\")\n",
    "\n",
    "    model.load_networks(file_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programa principal\n",
    "Treina o descriminador e gerador por `EPOCHS`, utilizando o material de treinamento presente em `FOLDER_NAME`. Checkpoints são salvos em `CKPT_DIR`. Informações sobre o status do treinamento são impressas no console e salvos pelo writer (caso definido que sim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    # Create the training data set\n",
    "    trainData = ImageFolderLoader(\n",
    "        f\"{FOLDER_NAME}/AB\", phase='train', preprocess='none')\n",
    "    trainSet = torch.utils.data.DataLoader(\n",
    "        trainData, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "    # Create the pix2pix model\n",
    "    model = Pix2PixModel(CKPT_DIR, MODEL_NAME, is_train=True,\n",
    "                         n_epochs=EPOCHS/2, n_epochs_decay=EPOCHS/2)\n",
    "\n",
    "    model.setup()\n",
    "    total_iters = 0\n",
    "\n",
    "    # Initiate the training iteration\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_start_time = time.time()\n",
    "        iter_data_time = time.time()\n",
    "        epoch_iter = 0\n",
    "\n",
    "        if epoch != 0:\n",
    "            model.update_learning_rate()\n",
    "\n",
    "        # Iterate through the data batches in the training set\n",
    "        for i, data in enumerate(trainSet):\n",
    "            iter_start_time = time.time()\n",
    "\n",
    "            # Setup counters\n",
    "            total_iters += BATCH_SIZE\n",
    "            epoch_iter += BATCH_SIZE\n",
    "\n",
    "            # Feed input through model, optimize parameters\n",
    "            model.set_input(data)\n",
    "            model.optimize_parameters()\n",
    "\n",
    "            # Use this for logging losses in tensorboard\n",
    "            if total_iters % PRINT_FREQ == 0:\n",
    "                losses = model.get_current_losses()\n",
    "                t_comp = (time.time() - iter_start_time) / BATCH_SIZE\n",
    "                print(\n",
    "                    f'Step {total_iters} | Epoch {epoch} | GAN Loss: {losses[\"G_GAN\"]:.3f} | Gen. L1: {losses[\"G_L1\"]:.3f} | Disc. real: {losses[\"D_real\"]:.3f} | Disc. fake: {losses[\"D_fake\"]:.3f}')\n",
    "\n",
    "            # Use this to log to tensorboard\n",
    "            if WRITE_LOGS and total_iters % LOG_FREQ == 0:\n",
    "                losses = model.get_current_losses().items()\n",
    "                for name, loss in losses:\n",
    "                    writer.add_scalar(name, loss, total_iters)  # type: ignore\n",
    "                writer.close()  # type: ignore\n",
    "\n",
    "            iter_data_time = time.time()\n",
    "\n",
    "        # Save checkpoints per epochs\n",
    "        if SAVE_CKPTS and epoch % CKPT_FREQ == 0:\n",
    "            print('Saving the model at the end of epoch %d, iters %d' %\n",
    "                  (epoch, total_iters))\n",
    "            model.save_network(epoch)\n",
    "\n",
    "            # Save image per checkpoint\n",
    "            if SAVE_IMG_CKPT:\n",
    "                print('Saving current epoch test to test folder')\n",
    "                visuals = model.get_current_visuals()\n",
    "                save_path = os.path.join(\n",
    "                    TEST_DIR, 'epoch_' + str(epoch) + '.jpg')\n",
    "                util.save_visuals(visuals, save_path)\n",
    "\n",
    "        # Print details at the end of the epoch\n",
    "        print('End of epoch %d / %d \\t Time Taken: %d secs' %\n",
    "              (epoch, EPOCHS -1, time.time() - epoch_start_time))\n",
    "\n",
    "    # Save / overwrite final epoch and image\n",
    "    if SAVE_CKPTS:\n",
    "        print('Saving the model at the end of training')\n",
    "        model.save_network(epoch)\n",
    "\n",
    "        if SAVE_IMG_CKPT:\n",
    "            print('Saving final epoch test to test folder')\n",
    "            visuals = model.get_current_visuals()\n",
    "            save_path = os.path.join(TEST_DIR, 'epoch_' + str(epoch) + '.jpg')\n",
    "            util.save_visuals(visuals, save_path)\n",
    "\n",
    "    # Plot last visuals from the model once training is complete\n",
    "    visuals = model.get_current_visuals()\n",
    "    util.plot_visuals(visuals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste do modelo\n",
    "Gera um leva de imagens, definidas por `TEST_SAMPLE`, utilizando as imagens que estão na pasta `test`. Carrega o modelo definido por `LOAD_NUMBER`. As imagens geradas são salvas em `TEST_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "        # Create the testing data set\n",
    "        testData = ImageFolderLoader(f'{FOLDER_NAME}/AB', phase='test', flip=False, preprocess='none')\n",
    "        testSet = torch.utils.data.DataLoader(testData, batch_size=BATCH_SIZE, shuffle= False, num_workers=0)\n",
    "\n",
    "        # Create the pix2pix model in testing mode\n",
    "        model = Pix2PixModel(CKPT_DIR, MODEL_NAME, is_train=False, n_epochs=EPOCHS/2, n_epochs_decay=EPOCHS/2)\n",
    "        model.setup()\n",
    "        model.eval()\n",
    "        load_model(model)\n",
    "\n",
    "        # Iterate through test data set, for the lenght of the test sample\n",
    "        for i, data in enumerate(testSet):\n",
    "            if i < TEST_SAMPLE:\n",
    "                model.set_input(data)\n",
    "                model.test()\n",
    "                visuals = model.get_current_visuals()\n",
    "                save_path = os.path.join(TEST_DIR, 'test_' + str(i) + '.jpg')\n",
    "                util.save_visuals(visuals, save_path)\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportação do modelo\n",
    "Para utilizar o modelo fora deste ambiente de treinamento, é preciso exportá-lo. Um modelo exportado no formato `.onnx` pode ser utilizado pelo Unity utilizando seu pacote `Barracuda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "Loading model from checkpoint 100 \n",
      "Generator is checkpoints\\tracos_run_1\\100_net_G.pth \n",
      "Discriminator is checkpoints\\tracos_run_1\\100_net_D.pth\n",
      "Loading the model from checkpoints\\tracos_run_1\\100_net_G.pth\n"
     ]
    }
   ],
   "source": [
    "if EXPORT_MODEL:\n",
    "        # Create dummy input\n",
    "        x = torch.randn(1, 3, 256, 256)\n",
    "\n",
    "        # Create the model and load the latest checkpoint\n",
    "        model = Pix2PixModel(CKPT_DIR, MODEL_NAME, is_train=False, n_epochs=EPOCHS/2, n_epochs_decay=EPOCHS/2)\n",
    "        model.setup()\n",
    "        model.eval()\n",
    "        load_model(model)\n",
    "\n",
    "        if not os.path.isdir('exported'):\n",
    "            os.makedirs('exported')\n",
    "        \n",
    "        path = os.path.join('exported', f'{MODEL_NAME}.onnx')\n",
    "        f = open(path, 'w+')\n",
    "\n",
    "        torch.onnx.export(model.netG, x.to(DEVICE), path, training=torch.onnx.TrainingMode.EVAL, export_params=True, opset_version=10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e71fdd7c552fe95a1eacb854f1b10e9ecb90034276b5430645f7c41b103f00ef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch-ready')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
